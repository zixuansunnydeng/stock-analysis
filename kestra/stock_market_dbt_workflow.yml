id: stock_market_dbt_workflow
namespace: stock_market_analysis

description: |
  This workflow orchestrates the stock market dbt transformations.
  It runs the dbt models in sequence and handles dependencies.

tasks:
  - id: setup_environment
    type: io.kestra.plugin.core.flow.WorkingDirectory
    tasks:
      - id: clone_repository
        type: io.kestra.plugin.git.Clone
        url: https://github.com/zixuansunnydeng/stock-analysis.git
        branch: main

      - id: install_dependencies
        type: io.kestra.plugin.scripts.shell.Commands
        commands:
          - pip install dbt-bigquery google-cloud-bigquery
        taskRunner:
          type: io.kestra.plugin.scripts.runner.docker.Docker
          containerImage: python:3.9

  - id: run_dbt_models
    type: io.kestra.plugin.dbt.cli.DbtCLI
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      containerImage: ghcr.io/dbt-labs/dbt-bigquery:1.5.1
    commands:
      - dbt deps
      - dbt run --models staging
      - dbt run --models intermediate
      - dbt run --models marts
    profiles: |
      stock_market:
        target: prod
        outputs:
          prod:
            type: bigquery
            method: service-account
            project: "{{ secret('GCP_PROJECT_ID') }}"
            dataset: stock_market_data
            threads: 4
            keyfile: "/app/kestra/service-account-key.json"
            timeout_seconds: 300
            location: us-central1
            priority: interactive

  - id: data_quality_checks
    type: io.kestra.plugin.scripts.python.Script
    inputFiles:
      service-account-key.json: "{{ secret('DBT_SERVICE_ACCOUNT_KEY') }}"
    script: |
      from google.cloud import bigquery
      from google.oauth2 import service_account
      import json
      import os

      # Set up credentials
      credentials = service_account.Credentials.from_service_account_file(
          '/app/kestra/service-account-key.json'
      )

      # Initialize BigQuery client
      client = bigquery.Client(credentials=credentials)

      # Define quality checks
      checks = [
          {
              "name": "Check stock_performance row count",
              "query": "SELECT COUNT(*) as count FROM `stock_market_data_marts.stock_performance`",
              "condition": lambda result: result > 0,
              "error_message": "No rows found in stock_performance table"
          },
          {
              "name": "Check for null values in key columns",
              "query": """
                  SELECT COUNT(*) as count
                  FROM `stock_market_data_marts.stock_performance`
                  WHERE month IS NULL OR avg_sp500_price IS NULL
              """,
              "condition": lambda result: result == 0,
              "error_message": "Null values found in key columns"
          }
      ]

      # Run checks
      results = []
      for check in checks:
          print(f"Running check: {check['name']}")
          query_job = client.query(check["query"])
          result = next(query_job.result())[0]
          passed = check["condition"](result)

          status = "PASSED" if passed else "FAILED"
          print(f"Check {check['name']}: {status}")

          if not passed:
              print(f"Error: {check['error_message']}")
              results.append({"name": check["name"], "status": status, "message": check["error_message"]})
          else:
              results.append({"name": check["name"], "status": status})

      # Output results as JSON
      print(json.dumps(results, indent=2))

      # Fail if any check failed
      if any(r["status"] == "FAILED" for r in results):
          exit(1)
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      containerImage: python:3.9

  - id: notify_success
    type: io.kestra.plugin.core.log.Log
    message: 'Stock market dbt workflow completed successfully!'

triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: '0 2 * * *' # Run daily at 2 AM

  - id: manual
    type: io.kestra.plugin.core.trigger.Flow
    inputs:
      run_mode:
        type: STRING
        required: false
        defaults: 'full'
